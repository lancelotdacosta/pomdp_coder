Certainly! Below is the implementation of the `transition_func` function that models the distribution of next states conditioned on actions and previous states based on the provided samples.

### Explanation:
The transition function primarily handles the movement and direction changes of the agent based on the action taken. Here's a breakdown of the logic:
- **Turning Actions (Left, Right)**: These actions change the agent's direction without moving its position.
- **Forward Action**: This action moves the agent one step forward in the direction it is facing, unless there is a wall or another obstacle.
- **Pickup, Drop, Toggle, Done Actions**: These actions are not represented in the given samples, so they do not alter the state in this implementation.

### Code Implementation:
```python
# type: ignore
from __future__ import annotations

from dataclasses import dataclass
from enum import IntEnum
from typing import Any, List, Optional, Tuple

import numpy as np
from numpy.typing import NDArray

AGENT_DIR_TO_STR = {0: ">", 1: "V", 2: "<", 3: "^"}
DIR_TO_VEC = [
    # Pointing right (positive X)
    np.array((1, 0)),
    # Down (positive Y)
    np.array((0, 1)),
    # Pointing left (negative X)
    np.array((-1, 0)),
    # Up (negative Y)
    np.array((0, -1)),
]

SEE_THROUGH_WALLS = True


class ObjectTypes(IntEnum):
    unseen = 0
    empty = 1
    wall = 2
    open_door = 4
    closed_door = 5
    locked_door = 6
    key = 7
    ball = 8
    box = 9
    goal = 10
    lava = 11
    agent = 12


class Direction(IntEnum):
    facing_right = 0
    facing_down = 1
    facing_left = 2
    facing_up = 3


class Actions(IntEnum):
    left = 0  # Turn left
    right = 1  # Turn right
    forward = 2  # Move forward
    pickup = 3  # Pick up an object
    drop = 4  # Drop an object
    toggle = 5  # Toggle/activate an object
    done = 6  # Done completing the task


@dataclass
class MinigridObservation:
    image: NDArray[np.int8]
    agent_pos: Tuple[int, int]
    agent_dir: int
    carrying: Optional[int] = None


@dataclass
class MinigridState:
    grid: NDArray[np.int8]
    agent_pos: Tuple[int, int]
    agent_dir: int
    carrying: Optional[int]

    @property
    def front_pos(self) -> Tuple[int, int]:
        return (np.array(self.agent_pos) + DIR_TO_VEC[self.agent_dir]).tolist()

    @property
    def width(self) -> int:
        return self.grid.shape[0]

    @property
    def height(self) -> int:
        return self.grid.shape[1]

    def get_type_indices(self, type: int) -> List[Tuple[int, int]]:
        idxs = np.where(self.grid == type)
        return list(zip(idxs[0], idxs[1]))

    def get_field_of_view(self, view_size: int) -> NDArray[np.int8]:
        topX, topY = 0, 0
        if self.agent_dir == 0:
            topX = self.agent_pos[0]
            topY = self.agent_pos[1] - view_size // 2
        elif self.agent_dir == 1:
            topX = self.agent_pos[0] - view_size // 2
            topY = self.agent_pos[1]
        elif self.agent_dir == 2:
            topX = self.agent_pos[0] - view_size + 1
            topY = self.agent_pos[1] - view_size // 2
        elif self.agent_dir == 3:
            topX = self.agent_pos[0] - view_size // 2
            topY = self.agent_pos[1] - view_size + 1

        fov = np.full((view_size, view_size), ObjectTypes.wall, dtype=self.grid.dtype)
        gx0, gy0 = max(topX, 0), max(topY, 0)
        gx1, gy1 = min(topX + view_size, self.grid.shape[0]), min(topY + view_size, self.grid.shape[1])
        px0, py0 = max(0, -topX), max(0, -topY)

        fov[px0 : px0 + (gx1 - gx0), py0 : py0 + (gy1 - gy0)] = self.grid[gx0:gx1, gy0:gy1]

        for _ in range(self.agent_dir + 1):
            fov = np.rot90(fov.T, k=1).T

        agent_pos = (self.grid.shape[0] // 2, self.grid.shape[1] - 1)
        self.grid[agent_pos] = ObjectTypes.agent

        return fov


def transition_func(state: MinigridState, action: int) -> MinigridState:
    new_state = MinigridState(
        grid=state.grid.copy(),
        agent_pos=state.agent_pos,
        agent_dir=state.agent_dir,
        carrying=state.carrying
    )

    if action == Actions.left:
        new_state.agent_dir = (new_state.agent_dir - 1) % 4
    elif action == Actions.right:
        new_state.agent_dir = (new_state.agent_dir + 1) % 4
    elif action == Actions.forward:
        front_pos = new_state.front_pos
        if front_pos[0] >= 0 and front_pos[1] >= 0 and front_pos[0] < new_state.width and front_pos[1] < new_state.height:
            if new_state.grid[front_pos] == ObjectTypes.empty:
                new_state.agent_pos = front_pos

    return new_state
```

This implementation ensures that the agent can turn left, turn right, and move forward based on its current direction and the environment grid. The agent will not move into walls or other obstacles.