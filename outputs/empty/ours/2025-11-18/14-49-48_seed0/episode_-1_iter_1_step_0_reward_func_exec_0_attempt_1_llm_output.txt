It looks like there might be an issue with the indentation or the structure of the code. Specifically, the `return` statements should be inside the `reward_func` function. Let's ensure that the function is properly formatted and indented.

Here is the corrected version of the `reward_func`:

```python
def reward_func(state, action, next_state):
    """
    Args:
        state (MinigridState): the state of the environment
        action (int): the action to be executed
        next_state (MinigridState): the next state of the environment
    Returns:
        reward (float): the reward of that state
        done (bool): whether the episode is done
    """
    
    # Check if the agent has reached the goal
    goal_positions = next_state.get_type_indices(ObjectTypes.goal)
    if any(next_state.agent_pos == pos for pos in goal_positions):
        return 1.0, True

    # Penalize for hitting a wall
    front_pos = next_state.front_pos
    if next_state.grid[front_pos] == ObjectTypes.wall and action == Actions.forward:
        return -1.0, False

    # Penalize for picking up an object when there is none
    if action == Actions.pickup and next_state.carrying is None:
        return -1.0, False

    # Penalize for dropping an object when the agent is not carrying one
    if action == Actions.drop and next_state.carrying is None:
        return -1.0, False

    # Penalize for toggling an object when it is not a door or other toggle-able object
    if action == Actions.toggle and next_state.grid[front_pos] not in [ObjectTypes.open_door, ObjectTypes.closed_door, ObjectTypes.locked_door]:
        return -1.0, False

    # Default reward for other actions
    return 0.0, False
```

### Explanation of Changes

1. **Indentation**: Ensure that all `return` statements are properly indented inside the `reward_func` function.
2. **Function Structure**: The function structure is correct with each condition checked and the appropriate reward and done flag returned.

This should resolve the `SyntaxError: 'return' outside function` issue. You can now use this function to model the reward conditioned on state, action, and next state transition in your environment.