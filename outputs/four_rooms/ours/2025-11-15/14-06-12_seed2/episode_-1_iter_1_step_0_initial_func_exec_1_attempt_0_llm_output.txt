The error you're encountering is due to the `np.random.choice` function expecting a 1-dimensional array, but `possible_goal_positions` is a list of tuples, which is inherently 2-dimensional. To fix this, you can convert the list of tuples into a 1-dimensional array and then use `np.random.choice` to select an index, which you can use to pick the corresponding tuple from the original list.

Here's the corrected implementation of the `initial_func` function:

```python
def initial_func(empty_state: MinigridState):
    """
    Input:
        empty_state (MinigridState): An empty state with only the walls filled into the grid
    Returns:
        state (MinigridState): the initial state of the environment
    """
    # The agent always starts at (1, 1) facing right (direction 0) and without carrying any object
    agent_pos = (1, 1)
    agent_dir = 0
    carrying = None

    # Create a copy of the grid to avoid modifying the empty_state directly
    grid = empty_state.grid.copy()

    # Place the goal in a random valid position
    possible_goal_positions = [
        (x, y) for x in range(1, grid.shape[0] - 1) for y in range(1, grid.shape[1] - 1)
        if grid[x, y] == ObjectTypes.empty
    ]
    
    if possible_goal_positions:
        # Convert the list of tuples to a 1-dimensional array of indices
        possible_goal_indices = np.arange(len(possible_goal_positions))
        # Choose a random index
        chosen_index = np.random.choice(possible_goal_indices)
        # Use the index to get the corresponding goal position
        goal_pos = possible_goal_positions[chosen_index]
        grid[goal_pos] = ObjectTypes.goal

    # Ensure the agent's starting position is an empty cell
    if grid[agent_pos] == ObjectTypes.empty:
        grid[agent_pos] = ObjectTypes.agent
    else:
        raise ValueError("Agent's starting position is not an empty cell")

    return MinigridState(grid=grid, agent_pos=agent_pos, agent_dir=agent_dir, carrying=carrying)
```

### Explanation:
1. **Generate Possible Goal Positions**: The list comprehension generates a list of tuples representing the possible positions for the goal.
2. **Convert to 1-Dimensional Array**: `possible_goal_indices` is created as a 1-dimensional array of indices corresponding to the possible goal positions.
3. **Choose a Random Index**: `np.random.choice` is used to select a random index from `possible_goal_indices`.
4. **Select the Goal Position**: The selected index is used to get the corresponding tuple from `possible_goal_positions`.
5. **Place the Goal**: The goal is placed at the selected position in the grid.
6. **Ensure Agent's Starting Position**: The agent's starting position (1, 1) is ensured to be an empty cell before placing the agent.

This should resolve the `ValueError: a must be 1-dimensional` issue and correctly initialize the environment state.