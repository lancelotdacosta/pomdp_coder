The error indicates that the agent's starting position (1, 1) is not an empty cell, which means it might already contain a wall or another object. To ensure the agent's starting position is always valid, we need to check and correct this condition.

One way to handle this is to ensure that the agent's starting position is empty before placing the agent there. If it is not empty, we can either raise an error or find another valid position for the agent. For simplicity, let's raise an error if the agent's starting position is not empty, as this will help identify and fix any issues with the initial grid setup.

Here is the updated `initial_func` function:

```python
def initial_func(empty_state: MinigridState):
    """
    Input:
        empty_state (MinigridState): An empty state with only the walls filled into the grid
    Returns:
        state (MinigridState): the initial state of the environment
    """
    # The agent always starts at (1, 1) facing right (direction 0) and without carrying any object
    agent_pos = (1, 1)
    agent_dir = 0
    carrying = None

    # Create a copy of the grid to avoid modifying the empty_state directly
    grid = empty_state.grid.copy()

    # Place the goal in a random valid position
    possible_goal_positions = [
        (x, y) for x in range(1, grid.shape[0] - 1) for y in range(1, grid.shape[1] - 1)
        if grid[x, y] == ObjectTypes.empty
    ]
    
    if possible_goal_positions:
        # Convert the list of tuples to a 1-dimensional array of indices
        possible_goal_indices = np.arange(len(possible_goal_positions))
        # Choose a random index
        chosen_index = np.random.choice(possible_goal_indices)
        # Use the index to get the corresponding goal position
        goal_pos = possible_goal_positions[chosen_index]
        grid[goal_pos] = ObjectTypes.goal

    # Ensure the agent's starting position is an empty cell
    if grid[agent_pos] != ObjectTypes.empty:
        raise ValueError("Agent's starting position is not an empty cell")

    grid[agent_pos] = ObjectTypes.agent

    return MinigridState(grid=grid, agent_pos=agent_pos, agent_dir=agent_dir, carrying=carrying)
```

### Explanation:
1. **Generate Possible Goal Positions**: The list comprehension generates a list of tuples representing the possible positions for the goal.
2. **Convert to 1-Dimensional Array**: `possible_goal_indices` is created as a 1-dimensional array of indices corresponding to the possible goal positions.
3. **Choose a Random Index**: `np.random.choice` is used to select a random index from `possible_goal_indices`.
4. **Select the Goal Position**: The selected index is used to get the corresponding tuple from `possible_goal_positions`.
5. **Place the Goal**: The goal is placed at the selected position in the grid.
6. **Ensure Agent's Starting Position**: Before placing the agent, we check if the agent's starting position (1, 1) is an empty cell. If it is not, we raise a `ValueError`. This will help identify and fix any issues with the initial grid setup.

This should ensure that the agent's starting position is always valid and prevent the `ValueError` from being raised.