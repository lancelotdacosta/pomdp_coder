Based on the provided samples, it appears that the observations are generated according to the following distribution:

- If the tiger is behind the left door (`tiger_location = LEFT`):
  - The agent hears the tiger on the left (`obs = 0`) with some probability.
  - The agent hears the tiger on the right (`obs = 1`) with some probability.
  - The agent hears nothing (`obs = 2`) with some probability.

- If the tiger is behind the right door (`tiger_location = RIGHT`):
  - The agent hears the tiger on the left (`obs = 0`) with some probability.
  - The agent hears the tiger on the right (`obs = 1`) with some probability.
  - The agent hears nothing (`obs = 2`) with some probability.

The action taken by the agent does not seem to affect the observation directly, but it might influence the probabilities. For simplicity, we will assume that the action `LISTEN` (action = 2) provides a better chance of hearing the correct side where the tiger is, while actions `OPEN_LEFT` (action = 0) and `OPEN_RIGHT` (action = 1) might still give some noise in the observations.

Here is the implementation of the `observation_func` function:

```python
from __future__ import annotations

import copy
import enum
import random
from dataclasses import dataclass
from typing import Any, Dict, List, Tuple

from uncertain_worms.structs import (
    Environment,
    Heuristic,
    InitialModel,
    Observation,
    ObservationModel,
    RewardModel,
    State,
    TransitionModel,
)


# --------------------------- Enums & Dataclasses -----------------------------#
class TigerObservationEnum(enum.IntEnum):
    """Possible observations the agent can receive."""
    HEAR_LEFT = 0, HEAR_RIGHT = 1, NONE = 2

class TigerActions(enum.IntEnum):
    """Agent actions in the classic Tiger problem."""
    OPEN_LEFT = 0
    OPEN_RIGHT = 1
    LISTEN = 2

@dataclass(frozen=True)
class TigerObservation(Observation):
    """Observation dataclass."""
    obs: int # 0 = hear left, 1 = hear right, 2 = none

@dataclass(frozen=True)
class TigerState(State):
    """Underlying hidden state: tiger behind LEFT (0) or RIGHT (1) door."""
    tiger_location: int  # 0 = left, 1 = right

def observation_func(state: TigerState, action: int, empty_obs: TigerObservation) -> TigerObservation:
    """
    Represents the non-centered field of view of the agent.

    The observation represents the agent's relative view of the world. 

    The agent is NOT in the center of the observation grid.

    Observation grids are always square-sizes (i.e. 3x3, 5x5, 7x7).

    The width and height of the observation grid are called view size.

    The agent is ALWAYS at obs.image[view_size // 2, view_size - 1] in the observation `image`

    Your may make use of the state.get_field_of_view helper function.

    Args:
        state (TigerState): the state of the environment
        action (int): the previous action that was taken
        empty_obs (TigerObservation): an empty observation that needs to be filled and returned
    Returns:
        obs (TigerObservation): observation of the agent
    """
    def generate_observation(tiger_location: int, action: int) -> int:
        if action == TigerActions.LISTEN:
            if tiger_location == TigerState(tiger_location=0).tiger_location:
                return random.choices([0, 1, 2], weights=[0.85, 0.05, 0.1])[0]
            elif tiger_location == TigerState(tiger_location=1).tiger_location:
                return random.choices([0, 1, 2], weights=[0.05, 0.85, 0.1])[0]
        else:
            if tiger_location == TigerState(tiger_location=0).tiger_location:
                return random.choices([0, 1, 2], weights=[0.6, 0.2, 0.2])[0]
            elif tiger_location == TigerState(tiger_location=1).tiger_location:
                return random.choices([0, 1, 2], weights=[0.2, 0.6, 0.2])[0]

    obs = generate_observation(state.tiger_location, action)
    return TigerObservation(obs=obs)
```

This function models the observation distribution based on the provided samples and the assumption that the `LISTEN` action provides more accurate observations compared to the other actions. The probabilities are chosen to reflect this behavior, with higher weights for the correct observation when listening and some noise for other actions.