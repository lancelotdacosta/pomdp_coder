It looks like the `LEFT` and `RIGHT` constants are not defined in the scope of the `reward_func`. Since these constants are used to represent the tiger's location, we need to define them within the function or use the constants from the `TigerActions` enum.

Here is the corrected `reward_func` with the necessary constants defined:

```python
def reward_func(state, action, next_state):
    """
    Args:
        state (TigerState): the state of the environment
        action (int): the action to be executed
        next_state (TigerState): the next state of the environment
    Returns:
        reward (float): the reward of that state
        done (bool): whether the episode is done
    """
    # Define constants for tiger locations
    LEFT = 0
    RIGHT = 1
    
    # Define the reward based on the action and the state transition
    if action == TigerActions.OPEN_LEFT:
        if state.tiger_location == LEFT:
            return -100.0, True  # Tiger was behind the left door, negative reward
        else:
            return 10.0, True  # Tiger was behind the right door, positive reward
    elif action == TigerActions.OPEN_RIGHT:
        if state.tiger_location == RIGHT:
            return -100.0, True  # Tiger was behind the right door, negative reward
        else:
            return 10.0, True  # Tiger was behind the left door, positive reward
    elif action == TigerActions.LISTEN:
        return 0.0, False  # Listening does not terminate the episode and gives no immediate reward
    
    # Default case (should not happen if actions are correctly defined)
    return 0.0, False
```

### Explanation
- **Constants**: `LEFT` and `RIGHT` are defined within the function to ensure they are available for use.
- **Reward Calculation**:
  - If the agent opens the door with the tiger, a large negative reward (-100.0) is given, and the episode ends (`done = True`).
  - If the agent opens the door without the tiger, a positive reward (10.0) is given, and the episode ends (`done = True`).
  - If the agent listens, no immediate reward is given (`reward = 0.0`), and the episode continues (`done = False`).

This should resolve the `NameError` and correctly implement the reward function.