Based on the provided samples, it appears that the `EXIT` action should only terminate the episode if the agent is at a specific exit location, which is not explicitly defined in the current implementation. The reward for the `CHECK_ROCK` actions should also provide a small negative reward when the agent is not at the rock being checked.

Here's the improved `reward_func` function:

```python
def reward_func(state: RockSampleState, action: int, next_state: RockSampleState) -> Tuple[float, bool]:
    """
    Args:
        state (RockSampleState): the state of the environment
        action (int): the action to be executed
        next_state (RockSampleState): the next state of the environment
    Returns:
        reward (float): the reward of that state
        done (bool): whether the episode is done
    """
    # Reward for sampling a rock
    if action == RockSampleActions.SAMPLE:
        rock_idx = state.at_rock()
        if rock_idx is not None:
            if state.rocks[rock_idx]:
                reward = 10.0  # Sampling a good rock gives a positive reward
            else:
                reward = -10.0  # Sampling a bad rock gives a negative reward
        else:
            reward = -10.0  # Sampling without being at a rock gives a negative reward
    # Reward for checking a rock
    elif action in CHECK_ACTIONS:
        rock_idx = state.at_rock()
        if rock_idx is not None and rock_idx == (action - RockSampleActions.CHECK_ROCK_0):
            reward = 0.0  # Checking the correct rock gives no reward
        else:
            reward = -1.0  # Checking without being at the rock or the wrong rock gives a small negative reward
    else:
        reward = 0.0  # No reward for other actions

    # Check if the episode is done
    if action == RockSampleActions.EXIT:
        # Episode is done only if the agent is at a specific exit location (e.g., (0, 0))
        if (state.x, state.y) == (0, 0):
            done = True
        else:
            done = False
    else:
        done = False

    return reward, done
```

### Explanation:
1. **Sampling a Rock**:
   - If the agent is at a rock and samples it, the reward is +10 for a good rock and -10 for a bad rock.
   - If the agent is not at a rock and tries to sample, the reward is -10.

2. **Checking a Rock**:
   - If the agent checks a rock and is at the correct rock, the reward is 0.
   - If the agent checks a rock but is not at the rock or checks the wrong rock, the reward is -1.

3. **Exiting the Environment**:
   - The episode is done only if the agent is at a specific exit location (e.g., (0, 0)) when the `EXIT` action is taken. Otherwise, the episode continues.

This implementation should better align with the observed samples from the real world.