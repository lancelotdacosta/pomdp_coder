Based on the observed samples, it appears that the reward is conditioned on the state, action, and the next state as follows:

1. **Sampling a Rock**:
   - If the agent performs a `SAMPLE` action while at a rock's position:
     - The reward is `10.0` if the rock is good (`True`).
     - The reward is `-1.0` if the rock is bad (`False`).
   - The rocks' quality should not change after sampling, but the reward should reflect the current state of the rock.

2. **Checking a Rock**:
   - If the agent performs a `CHECK_ROCK_0` or `CHECK_ROCK_1` action:
     - The reward is `-1.0` regardless of the rock's quality.
   - This action does not seem to change the state of the rocks or the environment.

3. **Exiting the Environment**:
   - If the agent performs an `EXIT` action:
     - The reward is `10.0`.
     - The episode ends (`done = True`).

4. **Other Actions**:
   - For other actions (like moving), the reward is `0.0` and the episode does not end.

Based on this understanding, I will update the `reward_func` function to better model the true distribution:

```python
def reward_func(state: RockSampleState, action: int, next_state: RockSampleState) -> Tuple[float, bool]:
    """
    Args:
        state (RockSampleState): the current state of the environment
        action (int): the action to be executed
        next_state (RockSampleState): the next state of the environment
    Returns:
        reward (float): the reward of that state
        done (bool): whether the episode is done
    """

    # Define the reward and done flags
    reward = 0.0
    done = False
    
    # Check if the action is to sample a rock
    if action == RockSampleActions.SAMPLE:
        rock_idx = state.at_rock()
        if rock_idx is not None:
            # If the agent is at a rock and samples it, get a reward based on the rock's quality
            if state.rocks[rock_idx]:
                reward = 10.0  # Good rock
            else:
                reward = -1.0  # Bad rock
    
    # Check if the action is to check a rock
    elif action in CHECK_ACTIONS:
        reward = -1.0  # Penalty for checking a rock
    
    # Check if the action is to exit the environment
    elif action == RockSampleActions.EXIT:
        reward = 10.0  # Large positive reward for exiting
        done = True  # Episode ends when the agent exits
    
    return reward, done
```

This updated function should now correctly reflect the observed behavior in the provided samples.