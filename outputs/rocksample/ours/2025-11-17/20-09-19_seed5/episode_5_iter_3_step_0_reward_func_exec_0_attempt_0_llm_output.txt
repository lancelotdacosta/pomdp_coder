Certainly! Let's analyze the reward conditions based on the discrepancies between the real world samples and your current model.

### Reward Conditions:
1. **Exiting the Grid**:
   - The agent should receive a reward of 10.0 if it performs the `EXIT` action and is at the exit point (0, 0).
   - If the agent attempts to exit from a different location, there should be no reward.

2. **Checking a Rock**:
   - If the agent performs a `CHECK_ROCK` action and is at a rock position, it should receive a reward of -1.0 regardless of the rock's state.
   - If the agent performs a `CHECK_ROCK` action but is not at a rock position, there should be no reward.

3. **Sampling a Rock**:
   - If the agent performs the `SAMPLE` action and is at a rock position with a good rock (G), it should receive a reward of 10.0 and the episode should end.
   - If the agent samples a bad rock (B), it should receive a reward of -10.0.
   - If the agent samples an empty location or a rock that has not been checked, there should be no reward.

4. **Other Actions**:
   - For all other actions, there should be no reward.

### Improved `reward_func` Function:
```python
def reward_func(state, action, next_state):
    """
    Args:
        state (RockSampleState): the state of the environment
        action (int): the action to be executed
        next_state (RockSampleState): the next state of the environment
    Returns:
        reward (float): the reward of that state
        done (bool): whether the episode is done
    """
    # Determine if the agent is at a rock position
    current_rock_idx = state.at_rock()
    next_rock_idx = next_state.at_rock()

    # Reward for exiting the grid (reaching the exit point)
    if action == RockSampleActions.EXIT and next_state.x == 0 and next_state.y == 0:
        return 10.0, True

    # Reward for checking a rock
    if action in CHECK_ACTIONS and current_rock_idx is not None:
        return -1.0, False

    # Reward for sampling a rock
    if action == RockSampleActions.SAMPLE:
        if current_rock_idx is not None:
            if state.rocks[current_rock_idx]:
                return 10.0, True
            else:
                return -10.0, False
        else:
            return 0.0, False

    # No reward for other actions
    return 0.0, False
```

### Explanation:
- **Exiting the Grid**: The condition `next_state.x == 0 and next_state.y == 0` ensures that the agent is at the exit point.
- **Checking a Rock**: The condition `current_rock_idx is not None` ensures that the agent is at a rock position.
- **Sampling a Rock**: The condition `current_rock_idx is not None` ensures that the agent is at a rock position. If the rock is good, the reward is 10.0 and the episode ends. If the rock is bad, the reward is -10.0. If the agent is not at a rock position, there is no reward.
- **Other Actions**: All other actions result in no reward.

This should better match the true distribution of rewards as observed in the real world samples.