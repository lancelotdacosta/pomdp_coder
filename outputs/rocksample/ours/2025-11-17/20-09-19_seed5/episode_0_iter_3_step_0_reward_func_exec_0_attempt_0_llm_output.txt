```python
def reward_func(state, action, next_state):
    """
    Args:
        state (RockSampleState): the state of the environment
        action (int): the action to be executed
        next_state (RockSampleState): the next state of the environment
    Returns:
        reward (float): the reward of that state
        done (bool): whether the episode is done
    """
    reward = 0.0
    done = False

    # Check if the agent is at a rock
    rock_idx = state.at_rock()

    if action == RockSampleActions.SAMPLE:
        if rock_idx is not None:
            # If the rock was good, the agent gets a positive reward
            if state.rocks[rock_idx]:
                reward = 10.0
                # The rock is now sampled and becomes bad
                next_rocks = list(next_state.rocks)
                next_rocks[rock_idx] = False
                next_state = RockSampleState(next_state.x, next_state.y, tuple(next_rocks))
            else:
                reward = 0.0
        else:
            # Sampling when not at a rock gives a negative reward
            reward = -1.0

    elif action == RockSampleActions.EXIT:
        # Exiting the environment ends the episode with a positive reward
        done = True
        reward = 10.0 if any(state.rocks) else 0.0

    elif action in CHECK_ACTIONS:
        # Checking a rock gives no immediate reward, but can provide information
        if rock_idx is not None and action == RockSampleActions.CHECK_ROCK_0 + rock_idx:
            # Simulate noisy observation (not implemented here)
            pass
        else:
            # Checking when not at a rock gives a negative reward
            reward = -1.0

    return reward, done
```

### Explanation of the Reward Function

1. **Sampling Action**:
   - If the agent is at a rock and samples it:
     - If the rock is good, the agent receives a positive reward (`10.0`).
     - The rock is marked as bad after sampling.
     - If the agent samples while not at a rock, it receives a negative reward (`-1.0`).

2. **Exit Action**:
   - Exiting the environment ends the episode.
   - The reward for exiting depends on whether any rocks are still good:
     - If there are any good rocks left, the agent receives a positive reward (`10.0`).
     - Otherwise, the reward is `0.0`.

3. **Check Actions**:
   - Checking a rock at the current position gives no immediate reward but can provide information.
   - If the agent checks a rock when not at a rock, it receives a negative reward (`-1.0`).

This updated reward function better aligns with the observed behavior in the real world by considering the state of the rocks and the agent's position more accurately.