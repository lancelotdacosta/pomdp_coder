```python
from __future__ import annotations

import copy
import enum
from dataclasses import dataclass
from typing import Any, Dict, List, Tuple

# -----------------------------------------------------------------------------#
# Domain parameters (feel free to tweak)                                       #
# -----------------------------------------------------------------------------#
NUM_ROCKS   = 2
GRID_SIZE   = 5
ROCK_POSITIONS = [(1, 1), (1, 4)]   # len == NUM_ROCKS

# -----------------------------------------------------------------------------#
# Actions                                                                      #
# -----------------------------------------------------------------------------#
class RockSampleActions(enum.IntEnum):
    """They can be added directly to the state position."""
    MOVE_NORTH  = 0
    MOVE_SOUTH  = 1
    MOVE_EAST   = 2
    MOVE_WEST   = 3
    SAMPLE      = 4
    EXIT        = 5

    CHECK_ROCK_0 = 6
    CHECK_ROCK_1 = 7


CHECK_ACTIONS: List[int] = [
    RockSampleActions.CHECK_ROCK_0,
    RockSampleActions.CHECK_ROCK_1,
]

# -----------------------------------------------------------------------------#
# Observation                                                                  #
# -----------------------------------------------------------------------------#
@dataclass
class RockSampleObservation(Observation):
    """Observation after an action.

    Always embeds the rover pose (x, y).  
    For sensor actions:
        * ``rock_idx``  – index of inspected rock
        * ``is_good``   – noisy reading (True = GOOD, False = BAD)
    For all other actions both fields are ``None``.
    """
    x: int
    y: int
    rock_idx: int | None
    is_good: bool | None

# -----------------------------------------------------------------------------#
# State                                                                        #
# -----------------------------------------------------------------------------#
@dataclass
class RockSampleState(State):
    """Full underlying state (fully observable to the simulator)."""
    x: int
    y: int
    rocks: Tuple[bool, ...]   # immutable tuple of good/bad flags

    # --- Equality / hashing --------------------------------------------------
    def __eq__(self, other: object) -> bool:                  # type: ignore[override]
        return (
            isinstance(other, RockSampleState)
            and self.x == other.x
            and self.y == other.y
            and self.rocks == other.rocks
        )

    # Convenience -------------------------------------------------------------
    def at_rock(self) -> int | None:
        """Return the index of the rock at the agent's (x,y) or ``None``."""
        try:
            return ROCK_POSITIONS.index((self.x, self.y))
        except ValueError:
            return None



def reward_func(state: RockSampleState, action: int, next_state: RockSampleState) -> Tuple[float, bool]:
    """
    Args:
        state (RockSampleState): the state of the environment
        action (int): the action to be executed
        next_state (RockSampleState): the next state of the environment
    Returns:
        reward (float): the reward of that state
        done (bool): whether the episode is done
    """
    
    # Reward and done flags
    reward = 0.0
    done = False
    
    # Check if the agent has taken the exit action
    if action == RockSampleActions.EXIT:
        done = True
        return reward, done

    # Check if the agent has sampled a rock
    if action == RockSampleActions.SAMPLE:
        rock_idx = state.at_rock()
        if rock_idx is not None:
            # If the agent samples a good rock, give a positive reward
            if next_state.rocks[rock_idx]:
                reward = 10.0
            else:
                reward = -1.0
        else:
            # Penalize for sampling when not at a rock
            reward = -1.0
    
    # No reward for other actions (move, check)
    return reward, done
```