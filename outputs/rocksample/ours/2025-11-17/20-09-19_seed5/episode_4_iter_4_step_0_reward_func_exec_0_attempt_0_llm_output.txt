Certainly! Let's analyze the problem and improve the `reward_func` function.

### Analysis
1. **Exit Action**:
   - The exit action should only provide a reward if the agent is at one of the valid exit locations: `(0, 0)` or `(GRID_SIZE - 1, GRID_SIZE - 1)`.
   - If the agent is at one of these locations, the episode should end (`done = True`).

2. **Sample Action**:
   - The sample action should provide a reward based on the quality of the rock at the current position.
   - If the agent is not at a rock, no reward should be given.

3. **Check Rock Actions**:
   - Check rock actions should always provide a small penalty, regardless of the agent's position.

### Issues in the Current Code
- The code incorrectly provides a reward of `10.0` and sets `done = True` for the exit action even when the agent is not at a valid exit location.
- The code fails to correctly handle the exit action for other positions.

### Improved Code
Here is the improved `reward_func` function:

```python
def reward_func(state: RockSampleState, action: int, next_state: RockSampleState) -> Tuple[float, bool]:
    """
    Args:
        state (RockSampleState): the state of the environment
        action (int): the action to be executed
        next_state (RockSampleState): the next state of the environment
    Returns:
        reward (float): the reward of that state
        done (bool): whether the episode is done
    """
    # Define the reward and done status
    reward = 0.0
    done = False

    # Check if the action is an exit action
    if action == RockSampleActions.EXIT:
        # Exit action should only provide a reward if the agent is at the exit location
        if (state.x, state.y) in [(0, 0), (GRID_SIZE - 1, GRID_SIZE - 1)]:
            reward = 10.0  # Reward for exiting from a valid exit location
            done = True
        else:
            reward = 0.0  # No reward for exiting from a non-exit location

    # Check if the action is a sample action
    if action == RockSampleActions.SAMPLE:
        rock_idx = state.at_rock()
        if rock_idx is not None:
            if state.rocks[rock_idx]:
                reward = 10.0  # Reward for sampling a good rock
            else:
                reward = -10.0  # Penalty for sampling a bad rock
        else:
            reward = 0.0  # No reward for sampling when not at a rock

    # Check if the action is a check rock action
    if action in CHECK_ACTIONS:
        rock_idx = action - RockSampleActions.CHECK_ROCK_0
        if rock_idx < len(ROCK_POSITIONS):
            reward = -1.0  # Small penalty for checking a rock

    return reward, done
```

### Explanation
- **Exit Action**:
  - The condition `(state.x, state.y) in [(0, 0), (GRID_SIZE - 1, GRID_SIZE - 1)]` ensures that the agent is at one of the valid exit locations.
  - If the agent is at a valid exit location, the reward is `10.0` and the episode ends (`done = True`).
  - If the agent is not at a valid exit location, the reward is `0.0` and the episode continues (`done = False`).

- **Sample Action**:
  - The function checks if the agent is at a rock using `state.at_rock()`.
  - If the agent is at a rock, the reward is determined based on the quality of the rock.
  - If the agent is not at a rock, no reward is given.

- **Check Rock Actions**:
  - The function always provides a small penalty of `-1.0` for check rock actions, regardless of the agent's position.

This improved function should better match the true distribution of rewards in the environment.