Certainly! Based on the provided samples, it appears that the reward function should consider not only the current state and action, but also how the rocks' states change. Here's the updated `reward_func` function that better models the true distribution:

```python
def reward_func(state, action, next_state):
    """
    Args:
        state (RockSampleState): the state of the environment
        action (int): the action to be executed
        next_state (RockSampleState): the next state of the environment
    Returns:
        reward (float): the reward of that state
        done (bool): whether the episode is done
    """
    
    # The reward is 10 if the agent samples a good rock
    if action == RockSampleActions.SAMPLE and state.at_rock() is not None:
        rock_idx = state.at_rock()
        if state.rocks[rock_idx] and not next_state.rocks[rock_idx]:
            return 10.0, False
        elif not state.rocks[rock_idx] and next_state.rocks[rock_idx]:
            return 10.0, False
        elif state.rocks[rock_idx] and next_state.rocks[rock_idx]:
            return 10.0, False
        elif not state.rocks[rock_idx] and not next_state.rocks[rock_idx]:
            return -10.0, False
    
    # The reward is -1 for check actions where the rock state changes
    if action in CHECK_ACTIONS and state.at_rock() is not None:
        rock_idx = state.at_rock()
        if state.rocks[rock_idx] != next_state.rocks[rock_idx]:
            return -1.0, False
    
    # The reward is 0 for all other actions
    if action in [RockSampleActions.MOVE_NORTH, RockSampleActions.MOVE_SOUTH, RockSampleActions.MOVE_EAST, RockSampleActions.MOVE_WEST] + CHECK_ACTIONS:
        return 0.0, False
    
    # The episode ends when the agent exits
    if action == RockSampleActions.EXIT:
        return 10.0, True
    
    # Default case: no reward, episode not done
    return 0.0, False
```

### Explanation:
1. ** Sampling a Rock:**
   - If the agent samples a rock, the reward depends on whether the rock's state changes.
   - If the rock was good and becomes bad, or if it was bad and becomes good, or if it remains good, the reward is 10.
   - If the rock was bad and remains bad, the reward is -10.

2. ** Checking a Rock:**
   - If the agent checks a rock and the rock's state changes (from good to bad or bad to good), the reward is -1.

3. ** Movement Actions:**
   - For moving actions (NORTH, SOUTH, EAST, WEST), the reward is 0.

4. ** Exiting:**
   - When the agent exits, the reward is 10 and the episode ends.

This function should better align with the observed distribution of rewards in the real environment.