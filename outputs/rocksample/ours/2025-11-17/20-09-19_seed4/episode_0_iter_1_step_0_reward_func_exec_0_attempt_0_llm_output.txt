Certainly! Let's first understand the reward structure based on the provided samples:

1. **Check Rock Actions (CHECK_ROCK_0, CHECK_ROCK_1)**:
   - If the agent is at the position of the rock being checked, the reward is -1.0.
   - Otherwise, the reward is 0.0.

2. **Sampling Action (SAMPLE)**:
   - If the agent is at the position of a rock and tries to sample it, the reward is -10.0.
   - Otherwise, the reward is 0.0.

3. **Exit Action (EXIT)**:
   - The episode should terminate with a done flag set to True.
   - The reward is 0.0 unless there are specific conditions for the state of the rocks, which are not provided in the samples.

4. **Movement Actions (MOVE_NORTH, MOVE_SOUTH, MOVE_EAST, MOVE_WEST)**:
   - No immediate reward for movement actions.
   - The episode does not terminate.

Based on this understanding, let's update the `reward_func` function:

```python
def reward_func(state: RockSampleState, action: int, next_state: RockSampleState) -> Tuple[float, bool]:
    """
    Args:
        state (RockSampleState): the state of the environment
        action (int): the action to be executed
        next_state (RockSampleState): the next state of the environment
    Returns:
        reward (float): the reward of that state
        done (bool): whether the episode is done
    """
    # Default reward and done flag
    reward = 0.0
    done = False

    # Handle movement actions
    if action in [RockSampleActions.MOVE_NORTH, RockSampleActions.MOVE_SOUTH, RockSampleActions.MOVE_EAST, RockSampleActions.MOVE_WEST]:
        # No immediate reward for movement actions
        pass

    # Handle sampling action
    elif action == RockSampleActions.SAMPLE:
        # If the agent is at a rock position, the reward is -10.0
        if state.at_rock() is not None:
            reward = -10.0

    # Handle exit action
    elif action == RockSampleActions.EXIT:
        # This could be a terminal action with potential reward
        done = True
        # Reward could be based on the state of the rocks or other conditions
        # For now, no specific reward condition is provided

    # Handle check rock actions
    elif action in CHECK_ACTIONS:
        # If the agent is at the rock position being checked, the reward is -1.0
        rock_idx = action - RockSampleActions.CHECK_ROCK_0
        if (state.x, state.y) == ROCK_POSITIONS[rock_idx]:
            reward = -1.0

    return reward, done
```

This updated function should better align with the observed distribution and handle the cases where the agent checks a rock or samples a rock. The `reward_func` now considers the specific conditions for each action type and updates the reward and done flag accordingly.