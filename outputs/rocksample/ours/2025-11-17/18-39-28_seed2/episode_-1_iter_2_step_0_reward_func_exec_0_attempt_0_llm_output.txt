Certainly! Let's start by explaining the reward conditioned on state, action, next state transition in English:

### Reward Function Explanation

1. **Exit Action (`EXIT`)**:
   - If the agent performs the `EXIT` action, it should receive a reward of 10.0 and the episode should be marked as done.
   - This is consistent across all states.

2. **Sample Action (`SAMPLE`)**:
   - If the agent performs the `SAMPLE` action and it is at a rock position:
     - If the rock is good (True), the agent should receive a reward of 10.0 and the episode should continue.
     - If the rock is bad (False), the agent should receive a reward of -10.0 and the episode should continue.
   - If the agent performs the `SAMPLE` action but is not at a rock position, the episode should continue with no reward change.

3. **Check Rock Actions (`CHECK_ROCK_0`, `CHECK_ROCK_1`)**:
   - If the agent performs a `CHECK_ROCK` action and is not at the corresponding rock position, the agent should receive a reward of -1.0 and the episode should continue.
   - If the agent performs a `CHECK_ROCK` action and is at the corresponding rock position, the episode should continue with no reward change.

4. **Move Actions (`MOVE_NORTH`, `MOVE_SOUTH`, `MOVE_EAST`, `MOVE_WEST`)**:
   - If the agent performs a move action, the episode should continue with no reward change.

### Improved Code

Here is the improved code for the `reward_func` function:

```python
def reward_func(state, action, next_state):
    """
    Args:
        state (RockSampleState): the state of the environment
        action (int): the action to be executed
        next_state (RockSampleState): the next state of the environment
    Returns:
        reward (float): the reward of that state
        done (bool): whether the episode is done
    """
    
    # Check if the agent has taken the exit action
    if action == RockSampleActions.EXIT:
        return 10.0, True

    # Check if the agent has sampled a rock
    if action == RockSampleActions.SAMPLE:
        rock_idx = state.at_rock()
        if rock_idx is not None:
            if state.rocks[rock_idx] == True:
                return 10.0, False
            else:
                return -10.0, False
        else:
            return 0.0, False

    # Check if the agent has performed a check rock action and is not at the corresponding rock
    if action in CHECK_ACTIONS:
        rock_idx = action - RockSampleActions.CHECK_ROCK_0
        if (state.x, state.y) != ROCK_POSITIONS[rock_idx]:
            return -1.0, False
        else:
            return 0.0, False

    # Check if the agent has moved or taken any other action
    if action in [RockSampleActions.MOVE_NORTH, RockSampleActions.MOVE_SOUTH, 
                  RockSampleActions.MOVE_EAST, RockSampleActions.MOVE_WEST]:
        return 0.0, False

    # Default case for any other actions
    return 0.0, False
```

This updated `reward_func` function should better align with the true distribution of rewards in the environment. The key changes include handling the `SAMPLE` action when the agent is not at a rock position and the `CHECK_ROCK` actions when the agent is not at the corresponding rock position.