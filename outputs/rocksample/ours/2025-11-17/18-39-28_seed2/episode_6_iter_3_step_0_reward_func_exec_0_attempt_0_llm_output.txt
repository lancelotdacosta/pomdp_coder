Certainly! Let's first explain the reward conditioned on state, action, and next state transition based on the provided examples and the environment description.

### Explanation

1. **Exiting the Grid**:
   - If the agent takes the `EXIT` action, it should receive a reward of 10.0 and the episode should end (`done = True`).

2. **Sampling a Rock**:
   - If the agent is at a rock and takes the `SAMPLE` action:
     - If the rock is good, the agent receives a reward of 10.0.
     - If the rock is bad, the agent receives a reward of -10.0.
   - If the agent takes the `SAMPLE` action but is not at a rock, it receives a penalty of -1.0.

3. **Checking a Rock**:
   - If the agent is at a rock and takes a `CHECK` action (e.g., `CHECK_ROCK_0` or `CHECK_ROCK_1`), it should receive a reward of 0.0.
   - If the agent takes a `CHECK` action but is not at a rock, it receives a penalty of -1.0.

4. **Moving Actions**:
   - For all other actions (i.e., moving actions like `MOVE_NORTH`, `MOVE_SOUTH`, etc.), the default reward is 0.0 and the episode does not end.

### Improved Code

Here is the improved `reward_func` function:

```python
def reward_func(state, action, next_state):
    """
    Args:
        state (RockSampleState): the state of the environment
        action (int): the action to be executed
        next_state (RockSampleState): the next state of the environment
    Returns:
        reward (float): the reward of that state
        done (bool): whether the episode is done
    """
    
    # Check if the agent has exited the grid
    if action == RockSampleActions.EXIT:
        return 10.0, True

    # Check if the agent is sampling a rock
    if action == RockSampleActions.SAMPLE:
        rock_idx = state.at_rock()
        if rock_idx is not None:
            if state.rocks[rock_idx]:  # Good rock
                return 10.0, False
            else:  # Bad rock
                return -10.0, False
        else:
            return -1.0, False  # Sampling but not at a rock

    # Check if the agent is checking a rock
    if action in CHECK_ACTIONS:
        rock_idx = state.at_rock()
        if rock_idx is not None:
            return 0.0, False
        else:
            return -1.0, False  # Checking but not at a rock

    # Default reward for moving actions
    return 0.0, False
```

### Explanation of Changes

1. **Exiting the Grid**:
   - The condition for exiting the grid remains the same.

2. **Sampling a Rock**:
   - The logic for sampling a rock is checked first to ensure it handles the scenario where the agent is not at a rock correctly.

3. **Checking a Rock**:
   - The logic for checking a rock is checked next to handle the scenario where the agent is not at a rock correctly.

4. **Moving Actions**:
   - The default reward for moving actions remains 0.0, and the episode does not end.

By ensuring that the function checks for the presence of rocks and the agent's position before applying rewards, we can better model the true distribution of the environment.