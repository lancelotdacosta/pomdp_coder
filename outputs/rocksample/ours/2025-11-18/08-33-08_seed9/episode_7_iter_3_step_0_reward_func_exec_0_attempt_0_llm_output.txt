Certainly! Let's first understand the reward function based on the provided samples and the environment description.

### Reward Function Explanation
1. **Sampling a Rock**:
   - If the agent is at a rock and takes the `SAMPLE` action, it should receive:
     - +10 if the rock is good (True).
     - -10 if the rock is bad (False).
     - -10 if the agent tries to sample when not at a rock.

2. **Exiting the Grid**:
   - If the agent takes the `EXIT` action, the episode should end (`done = True`), and the reward should be:
     - +10 if the agent is at a good rock when exiting.
     - -10 if the agent is at a bad rock when exiting.
     - 0 if the agent is not at a rock when exiting.

3. **Checking a Rock**:
   - If the agent takes a `CHECK_ROCK_X` action at the corresponding rock position, it should receive:
     - -1 (cost of checking a rock).

4. **Other Actions**:
   - For all other actions, the reward should be 0, and the episode should not end (`done = False`).

### Improved Code
Here is the improved `reward_func` function based on the above explanation:

```python
def reward_func(state, action, next_state):
    """
    Args:
        state (RockSampleState): the state of the environment
        action (int): the action to be executed
        next_state (RockSampleState): the next state of the environment
    Returns:
        reward (float): the reward of that state
        done (bool): whether the episode is done
    """
    reward = 0.0
    done = False

    # Check if the agent is at a rock and samples it
    if action == RockSampleActions.SAMPLE:
        rock_idx = state.at_rock()
        if rock_idx is not None:
            if state.rocks[rock_idx]:  # Good rock
                reward = 10.0
            else:  # Bad rock
                reward = -10.0
        else:
            reward = -10.0  # Sampling when not at a rock

    # Check if the agent exits the grid
    if action == RockSampleActions.EXIT:
        done = True
        rock_idx = state.at_rock()
        if rock_idx is not None:
            if state.rocks[rock_idx]:  # Good rock
                reward = 10.0
            else:  # Bad rock
                reward = -10.0
        else:
            reward = 0.0  # Not at a rock

    # Check if the agent checks a rock
    if action in CHECK_ACTIONS:
        rock_idx = CHECK_ACTIONS.index(action)
        if (state.x, state.y) == ROCK_POSITIONS[rock_idx]:
            reward = -1.0  # Cost of checking a rock

    return reward, done
```

This function should now correctly handle the reward and termination conditions based on the provided samples and the environment description.