Based on the provided samples, it appears that the distribution of initial states in the environment is as follows:

- **Agent Position**: The agent can start at various positions within the grid, but not on walls. The provided samples show the agent starting at different positions, such as (3, 3), (6, 2), (2, 6), and (4, 3).
- **Agent Direction**: The agent's initial direction can be any of the four cardinal directions: right (0), down (1), left (2), and up (3).
- **Carrying**: The agent starts without carrying any object (`carrying=None`).
- **Grid Layout**: The grid layout is consistent with the provided samples, where the outer edges are walls (2), and the inner cells are either empty (1) or contain a goal object (10).

Given this distribution, we can implement the `initial_func` function to sample an initial state that matches this distribution.

Here is the implementation of the `initial_func` function:

```python
# type: ignore
from __future__ import annotations

from dataclasses import dataclass
from enum import IntEnum
from typing import Any, List, Optional, Tuple

import numpy as np
from numpy.typing import NDArray

AGENT_DIR_TO_STR = {0: ">", 1: "V", 2: "<", 3: "^"}
DIR_TO_VEC = [
    # Pointing right (positive X)
    np.array((1, 0)),
    # Down (positive Y)
    np.array((0, 1)),
    # Pointing left (negative X)
    np.array((-1, 0)),
    # Up (negative Y)
    np.array((0, -1)),
]

SEE_THROUGH_WALLS = True


class ObjectTypes(IntEnum):
    unseen = 0
    empty = 1
    wall = 2
    open_door = 4
    closed_door = 5
    locked_door = 6
    key = 7
    ball = 8
    box = 9
    goal = 10
    lava = 11
    agent = 12


class Direction(IntEnum):
    facing_right = 0
    facing_down = 1
    facing_left = 2
    facing_up = 3


class Actions(IntEnum):
    left = 0  # Turn left
    right = 1  # Turn right
    forward = 2  # Move forward
    pickup = 3  # Pick up an object
    drop = 4  # Drop an object
    toggle = 5  # Toggle/activate an object
    done = 6  # Done completing the task


@dataclass
class MinigridObservation(Observation):
    """
    Args:
        `image`: field of view in front of the agent.

        `agent_pos`: agent's position in the real world. It differs from the position
                     in the observation grid.
        `agent_dir`: agent's direction in the real world. It differs from the direction
                     of the agent in the observation grid.
        `carrying`: what the agent is carrying at the moment.
    """

    image: NDArray[np.int8]
    agent_pos: Tuple[int, int]
    agent_dir: int
    carrying: Optional[int] = None


@dataclass
class MinigridState(State):
    """An agent exists in an indoor multi-room environment represented by a
    grid."""

    grid: NDArray[np.int8]
    agent_pos: Tuple[int, int]
    agent_dir: int
    carrying: Optional[int]

    @property
    def front_pos(self) -> Tuple[int, int]:
        """Get the position of the cell that is right in front of the agent."""

        return (
            np.array(self.agent_pos) + np.array(DIR_TO_VEC[self.agent_dir])
        ).tolist()

    @property
    def width(self) -> int:
        return self.grid.shape[0]

    @property
    def height(self) -> int:
        return self.grid.shape[1]

    def get_type_indices(self, type: int) -> List[Tuple[int, int]]:
        idxs = np.where(self.grid == type)  # Returns (row_indices, col_indices)
        return list(zip(idxs[0], idxs[1]))  # Combine row and column indices


def initial_func(empty_state: MinigridState) -> MinigridState:
    """
    Input:
        empty_state (MinigridState): An empty state with only the walls filled into the grid
    Returns:
        state (MinigridState): the initial state of the environment
    """
    # Ensure the agent starts in an empty cell, not on a wall or goal
    def is_valid_position(pos):
        return empty_state.grid[pos] == ObjectTypes.empty

    # Sample a random valid position for the agent
    while True:
        agent_pos = (np.random.randint(1, empty_state.width - 1), np.random.randint(1, empty_state.height - 1))
        if is_valid_position(agent_pos):
            break

    # Sample a random direction for the agent
    agent_dir = np.random.choice(list(Direction))

    # Create the initial state with the sampled position and direction
    initial_state = MinigridState(
        grid=empty_state.grid.copy(),
        agent_pos=agent_pos,
        agent_dir=agent_dir,
        carrying=None
    )

    # Place the agent in the grid
    initial_state.grid[agent_pos] = ObjectTypes.agent

    return initial_state
```

This implementation ensures that the agent starts in a valid position (not on a wall or goal) and with a random direction. The `is_valid_position` function checks if the sampled position is an empty cell. The `while` loop continues sampling positions until a valid one is found. The `agent_dir` is sampled from the list of directions. Finally, the initial state is created with the sampled position and direction, and the agent is placed in the grid.