#define system
You are a robot exploring its environment. 

Environment Description: 
Goal Description: 

Your goal is to model the the distribution of initial states . 
You need to implement the python code to model the world, as seen in the provided experiences. 
Please follow the template to implement the code. 
The code needs to be directly runnable an empty state with the walls of the grid pre-filled and return a sample initial state. 


Below are a few samples from the environment distribution. These are only samples from a larger distribution that your should model.

Output MinigridState: agent_pos=(4, 3)
agent_dir=1
carrying=None
grid=[
[ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2, 10,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2, ],
]



Output MinigridState: agent_pos=(2, 6)
agent_dir=0
carrying=None
grid=[
[ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1, 10,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2, ],
]



Output MinigridState: agent_pos=(3, 3)
agent_dir=2
carrying=None
grid=[
[ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2, ],
[ 2, 10,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2, ],
]



Output MinigridState: agent_pos=(4, 4)
agent_dir=3
carrying=None
grid=[
[ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2, ],
[ 2, 10,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2, ],
]



Output MinigridState: agent_pos=(2, 1)
agent_dir=2
carrying=None
grid=[
[ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  2, ],
[ 2,  1,  1,  1,  1,  1,  1,  1, 10,  2, ],
[ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2, ],
]





Here is the template for the initial_func function. Please implement
the reward function following the template. The code needs to be directly
runnable.

‘‘‘
# type: ignore
from __future__ import annotations

from dataclasses import dataclass
from enum import IntEnum
from typing import Any, List, Optional, Tuple

import numpy as np
from numpy.typing import NDArray

AGENT_DIR_TO_STR = {0: ">", 1: "V", 2: "<", 3: "^"}
DIR_TO_VEC = [
    # Pointing right (positive X)
    np.array((1, 0)),
    # Down (positive Y)
    np.array((0, 1)),
    # Pointing left (negative X)
    np.array((-1, 0)),
    # Up (negative Y)
    np.array((0, -1)),
]

SEE_THROUGH_WALLS = True


class ObjectTypes(IntEnum):
    unseen = 0
    empty = 1
    wall = 2
    open_door = 4
    closed_door = 5
    locked_door = 6
    key = 7
    ball = 8
    box = 9
    goal = 10
    lava = 11
    agent = 12


class Direction(IntEnum):
    facing_right = 0
    facing_down = 1
    facing_left = 2
    facing_up = 3


class Actions(IntEnum):
    left = 0  # Turn left
    right = 1  # Turn right
    forward = 2  # Move forward
    pickup = 3  # Pick up an object
    drop = 4  # Drop an object
    toggle = 5  # Toggle/activate an object
    done = 6  # Done completing the task


@dataclass
class MinigridObservation(Observation):
    """
    Args:
        `image`: field of view in front of the agent.

        `agent_pos`: agent's position in the real world. It differs from the position
                     in the observation grid.
        `agent_dir`: agent's direction in the real world. It differs from the direction
                     of the agent in the observation grid.
        `carrying`: what the agent is carrying at the moment.
    """

    image: NDArray[np.int8]
    agent_pos: Tuple[int, int]
    agent_dir: int
    carrying: Optional[int] = None


@dataclass
class MinigridState(State):
    """An agent exists in an indoor multi-room environment represented by a
    grid."""

    grid: NDArray[np.int8]
    agent_pos: Tuple[int, int]
    agent_dir: int
    carrying: Optional[int]

    @property
    def front_pos(self) -> Tuple[int, int]:
        """Get the position of the cell that is right in front of the agent."""

        return (
            np.array(self.agent_pos) + np.array(DIR_TO_VEC[self.agent_dir])
        ).tolist()

    @property
    def width(self) -> int:
        return self.grid.shape[0]

    @property
    def height(self) -> int:
        return self.grid.shape[1]

    def get_type_indices(self, type: int) -> List[Tuple[int, int]]:
        idxs = np.where(self.grid == type)  # Returns (row_indices, col_indices)
        return list(zip(idxs[0], idxs[1]))  # Combine row and column indices


    def get_field_of_view(self, view_size: int) -> NDArray[np.int8]:
        """Returns the field of view in front of the agent.

        DO NOT modify this function.
        """

        # Get the extents of the square set of tiles visible to the agent
        # Facing right
        if self.agent_dir == 0:
            topX = self.agent_pos[0]
            topY = self.agent_pos[1] - view_size // 2
        # Facing down
        elif self.agent_dir == 1:
            topX = self.agent_pos[0] - view_size // 2
            topY = self.agent_pos[1]
        # Facing left
        elif self.agent_dir == 2:
            topX = self.agent_pos[0] - view_size + 1
            topY = self.agent_pos[1] - view_size // 2
        # Facing up
        elif self.agent_dir == 3:
            topX = self.agent_pos[0] - view_size // 2
            topY = self.agent_pos[1] - view_size + 1
        else:
            assert False, "invalid agent direction"

        fov = np.full((view_size, view_size), ObjectTypes.wall, dtype=self.grid.dtype)

        # Compute the overlapping region in the grid.
        gx0 = max(topX, 0)
        gy0 = max(topY, 0)
        gx1 = min(topX + view_size, self.grid.shape[0])
        gy1 = min(topY + view_size, self.grid.shape[1])

        # Determine where the overlapping region goes in the padded array.
        px0 = max(0, -topX)
        py0 = max(0, -topY)

        # Copy the overlapping slice.
        fov[px0 : px0 + (gx1 - gx0), py0 : py0 + (gy1 - gy0)] = self.grid[
            gx0:gx1, gy0:gy1
        ]

        for _ in range(self.agent_dir + 1):
            # Rotate left
            fov = np.rot90(fov.T, k=1).T

        agent_pos = (self.grid.shape[0] // 2, self.grid.shape[1] - 1)
        self.grid[agent_pos] = ObjectTypes.agent

        return fov

def initial_func(empty_state:MinigridState):
    """
    Input:
        empty_state (MinigridState): An empty state with only the walls filled into the grid
    Returns:
        state (MinigridState): the initial state of the environment
    """
    raise NotImplementedError
‘‘‘

Explain what you believe is the the distribution of initial states  in english.
Additionally, please implement code to model the logic of the world. Please implement the 
code following the template. Only output the definition for ‘ initial_func ‘. 
You must implement the ‘ initial_func ‘ function.
Create any helper function inside the scope of ‘ initial_func ‘. 
Do not create any helper function outside the scope of ‘ initial_func ‘.
Do not output examples usage. 
Do not create any new classes.
Do not rewrite existing classes. 
Do not import any new modules from anywhere.
Do not overfit to the specific samples.
Put the ‘ initial_func ‘ function in a python code block.
#define assistant
Based on the provided samples, it appears that the distribution of initial states has the following characteristics:

1. **Agent Position**: The agent can start at various positions within the grid, but not on walls or goal cells. The provided samples show the agent starting at different locations such as (4, 3), (2, 6), (3, 3), (4, 4), and (2, 1).

2. **Agent Direction**: The agent's initial direction is randomly chosen from the four possible directions: right (0), down (1), left (2), up (3).

3. **Carrying State**: The agent does not carry any object in all provided samples.

4. **Grid Layout**: The grid has walls around the perimeter, and there is a single goal cell (10) somewhere in the grid. The rest of the cells are either empty (1) or contain the agent (12).

Given these observations, the `initial_func` function will randomly place the agent at a valid position (not on a wall or goal cell) and set a random direction for the agent. The grid will be pre-filled with walls, and a goal cell will be placed at a random position.

Here is the implementation of the `initial_func` function:

```python
def initial_func(empty_state: MinigridState):
    """
    Input:
        empty_state (MinigridState): An empty state with only the walls filled into the grid
    Returns:
        state (MinigridState): the initial state of the environment
    """
    
    def is_valid_position(grid, pos):
        """Check if the position is not a wall or a goal."""
        x, y = pos
        return grid[x][y] == ObjectTypes.empty
    
    def random_position(grid):
        """Return a random valid position in the grid."""
        valid_positions = [(x, y) for x in range(1, empty_state.width - 1) for y in range(1, empty_state.height - 1) if is_valid_position(grid, (x, y))]
        return np.random.choice(valid_positions)
    
    def random_direction():
        """Return a random direction for the agent."""
        return np.random.randint(4)
    
    # Place a goal cell at a random position
    goal_pos = random_position(empty_state.grid)
    empty_state.grid[goal_pos] = ObjectTypes.goal
    
    # Place the agent at a random valid position
    agent_pos = random_position(empty_state.grid)
    agent_dir = random_direction()
    
    # Ensure the grid is updated to reflect the agent's position
    empty_state.agent_pos = agent_pos
    empty_state.agent_dir = agent_dir
    empty_state.grid[agent_pos] = ObjectTypes.agent
    
    return empty_state
```

This function ensures that the agent is placed at a valid position and with a random direction, and a goal cell is placed at a random position in the grid. The grid is pre-filled with walls, and the rest of the cells are initially empty.
#define assistant


def initial_func(empty_state: MinigridState):
    """
    Input:
        empty_state (MinigridState): An empty state with only the walls filled into the grid
    Returns:
        state (MinigridState): the initial state of the environment
    """
    
    def is_valid_position(grid, pos):
        """Check if the position is not a wall or a goal."""
        x, y = pos
        return grid[x][y] == ObjectTypes.empty
    
    def random_position(grid):
        """Return a random valid position in the grid."""
        valid_positions = [(x, y) for x in range(1, empty_state.width - 1) for y in range(1, empty_state.height - 1) if is_valid_position(grid, (x, y))]
        return np.random.choice(valid_positions)
    
    def random_direction():
        """Return a random direction for the agent."""
        return np.random.randint(4)
    
    # Place a goal cell at a random position
    goal_pos = random_position(empty_state.grid)
    empty_state.grid[goal_pos] = ObjectTypes.goal
    
    # Place the agent at a random valid position
    agent_pos = random_position(empty_state.grid)
    agent_dir = random_direction()
    
    # Ensure the grid is updated to reflect the agent's position
    empty_state.agent_pos = agent_pos
    empty_state.agent_dir = agent_dir
    empty_state.grid[agent_pos] = ObjectTypes.agent
    
    return empty_state

#define user
Traceback (most recent call last):
  File "/pfs/data6/home/tu/tu_tu/tu_zxoau23/pomdp_coder/uncertain_worms/policies/partially_obs_planning_agent.py", line 212, in evaluate_initial_model
    model_initials[()] = [
                         ^
  File "/pfs/data6/home/tu/tu_tu/tu_zxoau23/pomdp_coder/uncertain_worms/policies/partially_obs_planning_agent.py", line 213, in <listcomp>
    (self.planner.initial_model(copy.deepcopy(self.empty_state)),)
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/tu/tu_tu/tu_zxoau23/pomdp_coder/uncertain_worms/policies/base_policy.py", line 83, in initial_model
    initial_state = locals()[func_name](empty_state)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "generated_code_initial_func200.py", line 26, in initial_func
    goal_pos = random_position(empty_state.grid)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "generated_code_initial_func200.py", line 19, in random_position
    return np.random.choice(valid_positions)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "numpy/random/mtrand.pyx", line 966, in numpy.random.mtrand.RandomState.choice
ValueError: a must be 1-dimensional

Traceback (most recent call last):
  File "/pfs/data6/home/tu/tu_tu/tu_zxoau23/pomdp_coder/uncertain_worms/policies/partially_obs_planning_agent.py", line 212, in evaluate_initial_model
    model_initials[()] = [
                         ^
  File "/pfs/data6/home/tu/tu_tu/tu_zxoau23/pomdp_coder/uncertain_worms/policies/partially_obs_planning_agent.py", line 213, in <listcomp>
    (self.planner.initial_model(copy.deepcopy(self.empty_state)),)
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/tu/tu_tu/tu_zxoau23/pomdp_coder/uncertain_worms/policies/base_policy.py", line 83, in initial_model
    initial_state = locals()[func_name](empty_state)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "generated_code_initial_func200.py", line 26, in initial_func
    goal_pos = random_position(empty_state.grid)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "generated_code_initial_func200.py", line 19, in random_position
    return np.random.choice(valid_positions)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "numpy/random/mtrand.pyx", line 966, in numpy.random.mtrand.RandomState.choice
ValueError: a must be 1-dimensional

